{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bab7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50125ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(\"\\n\\nMissing values:\\n\\n\", df.isnull().sum())\n",
    "print(\"\\nOutcome distribution:\\n\", df['HeartDisease'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3abc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train = df_shuffled.iloc[:3000]\n",
    "test = df_shuffled.iloc[3000:5600]\n",
    "print(f\"Train set shape: {train.shape}\")\n",
    "print(f\"Test set shape: {test.shape}\")\n",
    "X_train = train.iloc[:, :-1].values  # numpy array \n",
    "y_train = train.iloc[:, -1].values #Separates feature col (all except last - output ) \n",
    "X_test = test.iloc[:, :-1].values\n",
    "y_test = test.iloc[:, -1].values\n",
    "print(f\"\\nX_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2f58a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling (standardization)\n",
    "# Calculate mean and standard deviation of training features column-wise\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "train_std = np.std(X_train, axis=0)\n",
    "X_train_scaled = (X_train - train_mean) / train_std\n",
    "X_test_scaled = (X_test - train_mean) / train_std\n",
    "print(f\"Train mean: {np.mean(X_train_scaled, axis=0)}\")\n",
    "print(f\"Train std: {np.std(X_train_scaled, axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fe5f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.loss_curve = []\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.m,self.n=X.shape\n",
    "    \n",
    "    def update_weights(self, X, y):\n",
    "    \n",
    "    def predict(self, X):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83464e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LogisticRegression(learning_rate=0.01, n_iterations=1000)\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed7de28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b82b09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
